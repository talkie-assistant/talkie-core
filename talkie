#!/usr/bin/env bash
# Talkie service management CLI
# Usage: ./talkie [--dev|--production] <command> [options]
# Development: compose.yaml, build from source, Web UI via pipenv locally.
# Production: compose.production.yaml, image-only, Web UI in talkie-core container.

set -e

SCRIPT_DIR="$(cd "$(dirname "$0")" && pwd)"
cd "$SCRIPT_DIR"

# Parse --dev / --production before other args (so main sees command as $1)
while [ $# -gt 0 ]; do
    case "$1" in
        --dev|-d)
            export TALKIE_DEV=1
            shift
            ;;
        --production)
            export TALKIE_DEV=0
            shift
            ;;
        *)
            break
            ;;
    esac
done

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

log_info() {
    echo -e "${GREEN}[INFO]${NC} $1"
}

log_warn() {
    echo -e "${YELLOW}[WARN]${NC} $1"
}

log_error() {
    echo -e "${RED}[ERROR]${NC} $1"
}

log_debug() {
    echo -e "${BLUE}[DEBUG]${NC} $1"
}

# Development vs production mode.
# Dev: compose.yaml, build from source, Web UI via pipenv locally.
# Production: compose.production.yaml, image-only, Web UI in talkie-core container.
# Default: dev when inside repo (compose.yaml + modules/ present); else production.
_is_dev_mode() {
    if [ "${TALKIE_DEV:-}" = "1" ]; then return 0; fi
    if [ "${TALKIE_DEV:-}" = "0" ]; then return 1; fi
    [ -f "$SCRIPT_DIR/compose.yaml" ] && [ -d "$SCRIPT_DIR/modules" ] && return 0
    return 1
}

_is_production_mode() {
    _is_dev_mode && return 1 || return 0
}

# Compose file and service list depend on mode
_set_compose_mode() {
    if _is_dev_mode; then
        export COMPOSE_FILE="${COMPOSE_FILE:-$SCRIPT_DIR/compose.yaml}"
        COMPOSE_SERVICES="consul-server keydb haproxy chroma speech rag browser healthbeat"
    else
        export COMPOSE_FILE="${COMPOSE_FILE:-$SCRIPT_DIR/compose.production.yaml}"
        _production_services_list
    fi
}

# Build COMPOSE_SERVICES for production: infra + healthbeat + modules.enabled from config
_production_services_list() {
    local cfg="${TALKIE_CONFIG:-$SCRIPT_DIR/config.yaml}"
    local mods=""
    if [ -f "$cfg" ]; then
        # enabled: [speech, rag, browser] or multi-line enabled: - speech
        mods=$(grep -E 'enabled:\s*\[' "$cfg" 2>/dev/null | sed 's/.*enabled:\s*\[\([^]]*\)\].*/\1/' | tr ',' ' ' | tr -d '\r')
        if [ -z "$mods" ]; then
            mods=$(awk '/^modules:/,/^[a-z]/ { if (/^\s+-\s+/) { gsub(/^[[:space:]]*-[[:space:]]*/, ""); print } }' "$cfg" 2>/dev/null | tr '\n' ' ')
        fi
    fi
    [ -z "$mods" ] && mods="speech rag browser"
    COMPOSE_SERVICES="talkie-core consul-server keydb haproxy chroma $mods healthbeat"
}

# Check if podman is installed
check_podman() {
    if ! command -v podman &> /dev/null; then
        log_error "Podman is not installed."
        echo "Install Podman:"
        echo "  macOS: brew install podman"
        echo "  Linux: See https://podman.io/getting-started/installation"
        exit 1
    fi
}

# Check if podman-compose is available
check_podman_compose() {
    if command -v podman-compose &> /dev/null; then
        COMPOSE_CMD="podman-compose"
    elif podman compose version &> /dev/null 2>&1; then
        COMPOSE_CMD="podman compose"
    else
        log_error "podman-compose not found. Install it:"
        echo "  pip install podman-compose"
        echo "  or use podman compose (requires podman 4.0+)"
        exit 1
    fi
}

# Compose project name (directory name when not set); used for network name and compose
COMPOSE_PROJECT_NAME="${COMPOSE_PROJECT_NAME:-$(basename "$SCRIPT_DIR")}"
[ -z "$COMPOSE_PROJECT_NAME" ] && { log_warn "COMPOSE_PROJECT_NAME empty; using talkie-core"; COMPOSE_PROJECT_NAME="talkie-core"; }
export COMPOSE_PROJECT_NAME
CONTAINER_PREFIX="${COMPOSE_PROJECT_NAME}-"
# Single compose service names (for: ./talkie start haproxy, etc.). Ollama disabled (use local ollama serve).
COMPOSE_SERVICES="consul-server keydb haproxy chroma speech rag browser healthbeat"

# Initialize compose command and set COMPOSE_FILE / COMPOSE_SERVICES by mode
init_compose() {
    _set_compose_mode
    check_podman
    check_podman_compose
}

# Validate compose file and env before first up (fail fast on invalid YAML or missing env).
_validate_compose_config() {
    if ! $COMPOSE_CMD config >/dev/null 2>&1; then
        log_error "Compose config invalid. Run: $COMPOSE_CMD config"
        exit 1
    fi
}

# Stop and remove all project containers (so a conflicting network can be removed).
_stop_remove_talkie_containers() {
    local svc
    _set_compose_mode
    for svc in $COMPOSE_SERVICES; do
        podman stop "${CONTAINER_PREFIX}${svc}" 2>/dev/null || true
        podman rm -f "${CONTAINER_PREFIX}${svc}" 2>/dev/null || true
    done
}

# Remove any podman network using our subnet (172.30.0.0/24) that is not the current project's
# network, so compose can create talkie-core_talkie-core-network (or ${project}_talkie-core-network).
# Stops/removes talkie containers on conflicting networks if needed. Safe to call before start/restart and after stop.
clear_conflicting_talkie_networks() {
    local expected_net="${COMPOSE_PROJECT_NAME}_talkie-core-network"
    local net subnet
    while IFS= read -r net; do
        [ -z "$net" ] && continue
        subnet=$(podman network inspect "$net" --format '{{ range .Subnets }}{{ .Subnet }}{{ end }}' 2>/dev/null)
        if [ "$subnet" = "172.30.0.0/24" ] && [ "$net" != "$expected_net" ]; then
            log_info "Removing conflicting network $net (subnet 172.30.0.0/24) so current project network can be used."
            if podman network rm "$net" 2>/dev/null; then
                log_info "Removed $net"
            elif podman network rm -f "$net" 2>/dev/null; then
                log_info "Removed $net (and any containers attached to it)."
            else
                log_info "Stopping and removing talkie containers on $net, then removing network..."
                _stop_remove_talkie_containers
                sleep 1
                if podman network rm "$net" 2>/dev/null || podman network rm -f "$net" 2>/dev/null; then
                    log_info "Removed $net"
                else
                    log_warn "Could not remove $net."
                fi
            fi
        fi
    done < <(podman network ls --format '{{.Name}}' 2>/dev/null)
}

# Ensure talkie network exists (matches compose.yaml: subnet 172.30.0.0/24, labels for Docker Compose)
# Only used when project name is "talkie" (legacy); otherwise compose creates the network.
ensure_talkie_network() {
    if ! podman network exists talkie_talkie-network 2>/dev/null; then
        log_info "Creating talkie network (talkie_talkie-network)..."
        podman network create \
            --driver bridge \
            --subnet 172.30.0.0/24 \
            --label com.docker.compose.project=talkie \
            --label com.docker.compose.network=talkie-network \
            --label io.podman.compose.project=talkie \
            talkie_talkie-network
    fi
}

# Start services
cmd_start() {
    local services="${1:-all}"
    local svc

    if [ "$services" = "web" ]; then
        cmd_web_start
        return
    fi
    init_compose
    for svc in $COMPOSE_SERVICES; do
        if [ "$services" = "$svc" ]; then
            init_compose
            _validate_compose_config
            clear_conflicting_talkie_networks
            log_info "Starting $services..."
            if ! $COMPOSE_CMD up -d "$services"; then
                log_info "Starting existing container ${CONTAINER_PREFIX}$services..."
                podman start "${CONTAINER_PREFIX}$services" || { log_error "Failed to start ${CONTAINER_PREFIX}$services"; return 1; }
            fi
            return
        fi
    done

    init_compose
    _validate_compose_config
    log_info "Starting Talkie services..."

    if [ "$services" = "all" ]; then
        clear_conflicting_talkie_networks
        [ "$COMPOSE_PROJECT_NAME" = "talkie" ] && ensure_talkie_network
        if _is_production_mode; then
            log_info "Production mode: pulling images then starting services..."
            $COMPOSE_CMD pull $COMPOSE_SERVICES 2>/dev/null || true
            if ! $COMPOSE_CMD up -d $COMPOSE_SERVICES; then
                log_info "Recreating network and retrying..."
                for svc in $COMPOSE_SERVICES; do
                    podman stop "${CONTAINER_PREFIX}${svc}" 2>/dev/null || true
                done
                clear_conflicting_talkie_networks
                sleep 1
                $COMPOSE_CMD up -d $COMPOSE_SERVICES
            fi
            log_info "All services started (Web UI in talkie-core container). http://localhost:8765"
        else
            if ! $COMPOSE_CMD up -d $COMPOSE_SERVICES; then
                log_info "Recreating network and retrying..."
                for svc in $COMPOSE_SERVICES; do
                    podman stop "${CONTAINER_PREFIX}${svc}" 2>/dev/null || true
                done
                clear_conflicting_talkie_networks
                sleep 1
                $COMPOSE_CMD up -d $COMPOSE_SERVICES
            fi
            log_info "Starting Web UI (background)..."
            cmd_web_start
            log_info "All services started"
        fi
        cmd_status
    elif [ "$services" = "core" ]; then
        clear_conflicting_talkie_networks
        log_info "Starting core services (Chroma; Ollama is local)..."
        $COMPOSE_CMD up -d chroma
    elif [ "$services" = "modules" ]; then
        clear_conflicting_talkie_networks
        log_info "Starting module servers..."
        if _is_production_mode; then
            local mods=""
            [ -f "${TALKIE_CONFIG:-$SCRIPT_DIR/config.yaml}" ] && mods=$(grep -E 'enabled:\s*\[' "${TALKIE_CONFIG:-$SCRIPT_DIR/config.yaml}" 2>/dev/null | sed 's/.*enabled:\s*\[\([^]]*\)\].*/\1/' | tr ',' ' ' | tr -d '\r')
            [ -z "$mods" ] && mods="speech rag browser"
            $COMPOSE_CMD up -d $mods healthbeat
        else
            $COMPOSE_CMD up -d speech rag browser healthbeat
        fi
    fi

    if [ "$services" = "all" ]; then
        :
    elif [ "$services" = "core" ] || [ "$services" = "modules" ]; then
        log_info "Services started"
    else
        log_warn "Unknown target: $services. Use: all, core, modules, or a service name (e.g. consul-server, keydb, haproxy)."
    fi
}

# Stop services
cmd_stop() {
    local services="${1:-all}"
    local svc

    if [ "$services" = "web" ]; then
        cmd_web_stop
        return
    fi
    for svc in $COMPOSE_SERVICES; do
        if [ "$services" = "$svc" ]; then
            init_compose
            log_info "Stopping $services..."
            $COMPOSE_CMD stop "$services" 2>/dev/null || true
            log_info "Services stopped"
            return
        fi
    done

    init_compose
    log_info "Stopping Talkie services..."

    if [ "$services" = "all" ]; then
        cmd_web_stop
        if _is_production_mode; then
            log_info "Stopping all production services..."
            $COMPOSE_CMD stop $COMPOSE_SERVICES 2>/dev/null || true
            clear_conflicting_talkie_networks
        fi
    fi

    if [ "$services" != "all" ] || ! _is_production_mode; then
        if [ "$services" = "all" ] || [ "$services" = "modules" ]; then
            log_info "Stopping module servers..."
            $COMPOSE_CMD stop speech rag browser healthbeat 2>/dev/null || true
        fi

        if [ "$services" = "all" ] || [ "$services" = "core" ]; then
            log_info "Stopping core services..."
            $COMPOSE_CMD stop chroma 2>/dev/null || true
        fi

        if [ "$services" = "all" ]; then
            log_info "Stopping infrastructure services..."
            for svc in consul-server keydb haproxy; do
                $COMPOSE_CMD stop "$svc" 2>/dev/null || true
            done
            clear_conflicting_talkie_networks
        fi
    fi

    log_info "Services stopped"
}

# Restart services (use compose restart for containers to avoid "name already in use")
cmd_restart() {
    local services="${1:-all}"
    local svc

    log_info "Restarting services: $services"

    if [ "$services" = "web" ]; then
        cmd_web_restart
        return
    fi
    init_compose
    for svc in $COMPOSE_SERVICES; do
        if [ "$services" = "$svc" ]; then
            if _is_production_mode; then
                log_info "Recreating $services container..."
                $COMPOSE_CMD up -d --force-recreate "$services"
            else
                log_info "Building $services (so code changes are in the image)..."
                $COMPOSE_CMD build "$services"
                log_info "Recreating $services container..."
                $COMPOSE_CMD up -d --force-recreate "$services"
            fi
            return
        fi
    done

    if [ "$services" = "all" ]; then
        log_info "Stopping all services..."
        cmd_stop "all"
        sleep 2
        if ! _is_production_mode; then
            log_info "Building images (if needed due to changes)..."
            $COMPOSE_CMD build
        fi
        log_info "Starting all services..."
        cmd_start "all"
        return
    fi

    # core | modules (or unknown target)
    init_compose
    cmd_stop "$services"
    sleep 1
    cmd_start "$services"
}

# Web server PID file (logs go to talkie.log via app config)
WEB_PID_FILE="$SCRIPT_DIR/.talkie-web.pid"

cmd_web_start() {
    if _is_production_mode; then
        init_compose
        _validate_compose_config
        log_info "Starting Talkie Web UI (talkie-core container)..."
        $COMPOSE_CMD pull talkie-core 2>/dev/null || true
        $COMPOSE_CMD up -d talkie-core
        log_info "Web UI running in container. http://localhost:8765"
        return
    fi
    if [ -f "$WEB_PID_FILE" ]; then
        local pid
        pid=$(cat "$WEB_PID_FILE")
        if kill -0 "$pid" 2>/dev/null; then
            log_info "Web UI already running (PID $pid). http://localhost:8765"
            return 0
        fi
        rm -f "$WEB_PID_FILE"
    fi
    # If port 8765 is in use (e.g. stale process), free it before starting
    if command -v lsof &>/dev/null; then
        local port_pid
        port_pid=$(lsof -ti :8765 2>/dev/null | head -1)
        if [ -n "$port_pid" ]; then
            log_info "Killing process $port_pid holding port 8765"
            kill "$port_pid" 2>/dev/null || true
            sleep 2
        fi
    fi
    log_info "Starting Talkie Web UI..."
    ( cd "$SCRIPT_DIR" && nohup pipenv run python run_web.py >> talkie.log 2>&1 & echo $! > "$WEB_PID_FILE" )
    sleep 1
    if [ -f "$WEB_PID_FILE" ] && kill -0 "$(cat "$WEB_PID_FILE")" 2>/dev/null; then
        log_info "Web UI started (PID $(cat "$WEB_PID_FILE")). http://localhost:8765"
    else
        log_error "Web UI failed to start. Check talkie.log"
        rm -f "$WEB_PID_FILE"
        exit 1
    fi
}

cmd_web_stop() {
    if _is_production_mode; then
        init_compose
        log_info "Stopping Talkie Web UI (talkie-core container)..."
        $COMPOSE_CMD stop talkie-core 2>/dev/null || true
        log_info "Web UI container stopped"
        return
    fi
    if [ -f "$WEB_PID_FILE" ]; then
        local pid
        pid=$(cat "$WEB_PID_FILE")
        if kill -0 "$pid" 2>/dev/null; then
            kill "$pid" 2>/dev/null || true
            sleep 1
            kill -9 "$pid" 2>/dev/null || true
        fi
        rm -f "$WEB_PID_FILE"
        log_info "Web UI stopped"
    else
        log_info "Web UI not running"
    fi
}

cmd_web_restart() {
    cmd_web_stop
    sleep 1
    cmd_web_start
}

# Check if port 8765 is listening (macOS and Linux)
web_port_listening() {
    if command -v lsof &>/dev/null; then
        lsof -i :8765 2>/dev/null | grep -q LISTEN
    else
        [ -n "$(ss -tln 2>/dev/null | grep ':8765 ')" ] || [ -n "$(netstat -tln 2>/dev/null | grep ':8765 ')" ]
    fi
}

cmd_web_status() {
    if _is_production_mode; then
        init_compose
        if podman ps --format "{{.Names}}" | grep -q "^${CONTAINER_PREFIX}talkie-core$"; then
            if curl -s -f http://localhost:8765/ > /dev/null 2>&1; then
                echo -e "Web UI: ${GREEN}running${NC} (talkie-core container). http://localhost:8765"
            else
                echo -e "Web UI: container running but ${YELLOW}port 8765 not responding${NC}"
            fi
        else
            echo -e "Web UI: ${RED}stopped${NC}. Run: ./talkie start web"
        fi
        return
    fi
    if [ -f "$WEB_PID_FILE" ]; then
        local pid
        pid=$(cat "$WEB_PID_FILE")
        if kill -0 "$pid" 2>/dev/null; then
            if web_port_listening; then
                echo -e "Web UI: ${GREEN}running${NC} (PID $pid, port 8765). http://localhost:8765"
            else
                echo -e "Web UI: process running (PID $pid) but ${YELLOW}port 8765 not listening${NC}. Check talkie.log"
            fi
        else
            echo -e "Web UI: ${RED}stopped${NC} (stale PID file removed)"
            rm -f "$WEB_PID_FILE"
        fi
    else
        if web_port_listening; then
            echo -e "Web UI: port 8765 in use by another process (not managed by talkie)"
        else
            echo -e "Web UI: ${RED}stopped${NC}. Run: ./talkie start web"
        fi
    fi
}

# --- App command (replaces start.sh): bring up services then run UI ---
is_container_running() {
    local container_name=$1
    podman ps --format "{{.Names}}" | grep -q "^${container_name}$"
}

app_check_container_health() {
    local container_name=$1
    local max_attempts=${2:-10}
    local attempt=0
    while [ $attempt -lt $max_attempts ]; do
        local health
        health=$(podman inspect --format='{{.State.Health.Status}}' "$container_name" 2>/dev/null || echo "none")
        if [ "$health" = "healthy" ]; then return 0; fi
        if [ "$health" = "unhealthy" ]; then return 1; fi
        if [ "$health" = "none" ] || [ "$health" = "" ]; then
            is_container_running "$container_name" && return 0 || return 1
        fi
        attempt=$((attempt + 1))
        sleep 1
    done
    return 1
}

app_health_check_service() {
    local service_name=$1
    local container_name=$2
    local check_url=$3
    if ! is_container_running "$container_name"; then
        log_warn "$service_name container ($container_name) is not running"
        return 1
    fi
    if [ -n "$check_url" ]; then
        if curl -s -f "$check_url" > /dev/null 2>&1; then
            log_info "$service_name is healthy"
            return 0
        else
            log_warn "$service_name is running but health check failed at $check_url"
            return 1
        fi
    fi
    if app_check_container_health "$container_name" 3; then
        log_info "$service_name is healthy"
        return 0
    else
        log_warn "$service_name container exists but health check failed"
        return 1
    fi
}

app_check_python() {
    if ! command -v python3 &> /dev/null; then
        log_error "Python 3 is not installed."
        echo "Install Python 3.11+: macOS: brew install python@3.11"
        exit 1
    fi
    log_info "Python found: $(python3 --version 2>&1)"
    if ! command -v pipenv &> /dev/null; then
        log_warn "pipenv not found. Installing..."
        pip3 install --user pipenv || { log_error "Failed to install pipenv."; exit 1; }
        export PATH="$HOME/.local/bin:$PATH"
    fi
    log_info "pipenv found: $(pipenv --version)"
}

app_install_deps() {
    local need_install=false
    if [ ! -f "Pipfile.lock" ] || [ "Pipfile" -nt "Pipfile.lock" ]; then need_install=true; fi
    if [ "$need_install" = true ]; then
        log_info "Installing/updating Python dependencies..."
        pipenv install --dev || { log_error "Failed to install dependencies."; exit 1; }
    else
        if ! pipenv --venv &> /dev/null; then
            pipenv install --dev || { log_error "Failed to install dependencies."; exit 1; }
        fi
    fi
}

app_setup_data_dir() {
    [ ! -d "data" ] && mkdir -p data
    if [ ! -f "config.yaml" ]; then
        log_error "config.yaml not found."
        exit 1
    fi
}

# Register chroma (and optionally ollama) with Consul so *.service.consul resolves. Ollama disabled (local).
app_register_consul_services() {
    if ! is_container_running "${CONTAINER_PREFIX}consul-server"; then
        return
    fi
    local consul_addr="http://localhost:8500"
    if ! curl -s -f "${consul_addr}/v1/status/leader" > /dev/null 2>&1; then
        log_debug "Consul not reachable; skipping service registration"
        return
    fi
    for name in chroma; do
        local cid port
        case "$name" in
            chroma) cid="${CONTAINER_PREFIX}chroma"; port=8000 ;;
            *) continue ;;
        esac
        if ! is_container_running "$cid"; then
            continue
        fi
        local ip
        ip=$(podman inspect --format '{{range .NetworkSettings.Networks}}{{.IPAddress}}{{end}}' "$cid" 2>/dev/null | head -1)
        if [ -z "$ip" ]; then
            ip=$(podman inspect --format '{{.NetworkSettings.IPAddress}}' "$cid" 2>/dev/null)
        fi
        if [ -z "$ip" ]; then
            log_debug "Could not get IP for $cid; skipping Consul registration"
            continue
        fi
        local payload
        payload=$(printf '{"ID":"%s-1","Name":"%s","Address":"%s","Port":%s}' "$name" "$name" "$ip" "$port")
        if curl -s -X PUT -d "$payload" "${consul_addr}/v1/agent/service/register" > /dev/null 2>&1; then
            log_debug "Registered $name with Consul at $ip:$port"
        else
            log_debug "Consul registration failed for $name"
        fi
    done
}

# Check local Ollama (no Podman container). Ensure model is available and warm up.
app_check_ollama_models() {
    log_info "Checking local Ollama..."
    if ! curl -s http://localhost:11434/api/tags > /dev/null 2>&1; then
        log_info "Waiting for Ollama (run: ollama serve)..."
        sleep 10
        if ! curl -s http://localhost:11434/api/tags > /dev/null 2>&1; then
            log_error "Ollama not responding at http://localhost:11434. Run: ollama serve"
            exit 1
        fi
    fi
    local DEFAULT_MODEL=phi
    [ -f config.yaml ] && DEFAULT_MODEL=$(grep -E "^\s*model_name:" config.yaml | head -1 | sed 's/.*model_name:\s*\([^ ]*\).*/\1/' | tr -d '"' || echo "phi")
    local MODELS_JSON MODELS MODEL_FOR_API
    MODELS_JSON=$(curl -s http://localhost:11434/api/tags 2>/dev/null || echo "{}")
    MODELS=$(echo "$MODELS_JSON" | grep -o '"name":"[^"]*"' | cut -d'"' -f4 || echo "")
    if ! echo "$MODELS" | grep -qE "^${DEFAULT_MODEL}(:|$)"; then
        log_info "Pulling model '$DEFAULT_MODEL' (local ollama)..."
        ollama pull "$DEFAULT_MODEL" || { log_warn "ollama pull failed; ensure ollama is on PATH"; }
        MODELS_JSON=$(curl -s http://localhost:11434/api/tags 2>/dev/null || echo "{}")
        MODELS=$(echo "$MODELS_JSON" | grep -o '"name":"[^"]*"' | cut -d'"' -f4 || echo "")
    fi
    log_info "Warming up Ollama model '$DEFAULT_MODEL'..."
    MODEL_FOR_API=$(echo "$MODELS" | grep -E "^${DEFAULT_MODEL}(:|$)" | head -1)
    [ -z "$MODEL_FOR_API" ] && MODEL_FOR_API="$DEFAULT_MODEL"
    if ! curl -s -X POST http://localhost:11434/api/generate -H "Content-Type: application/json" \
        -d "{\"model\":\"$MODEL_FOR_API\",\"prompt\":\"ok\",\"stream\":false}" --max-time 90 > /dev/null 2>&1; then
        log_warn "Ollama warmup failed (first request may 500)."
    fi
    if [ -f config.yaml ] && grep -q "embedding_model:" config.yaml; then
        local EMBED_MODEL
        EMBED_MODEL=$(grep -E "^\s*embedding_model:" config.yaml | head -1 | sed 's/.*embedding_model:\s*\([^ ]*\).*/\1/' | tr -d '"' || echo "")
        if [ -n "$EMBED_MODEL" ] && ! echo "$MODELS" | grep -qE "^${EMBED_MODEL}(:|$)"; then
            log_info "Pulling embedding model '$EMBED_MODEL' (local ollama)..."
            ollama pull "$EMBED_MODEL" || true
        fi
    fi
}

cmd_app() {
    local LOCAL_ONLY=0
    while [ $# -gt 0 ]; do
        case "$1" in
            --local-only) LOCAL_ONLY=1; shift ;;
            *) break ;;
        esac
    done
    init_compose
    _validate_compose_config
    if _is_production_mode; then
        log_info "Starting Talkie (production: all services from images, Web UI in talkie-core container)..."
        clear_conflicting_talkie_networks
        log_info "Pulling images..."
        $COMPOSE_CMD pull $COMPOSE_SERVICES 2>/dev/null || true
        log_info "Starting services..."
        $COMPOSE_CMD up -d $COMPOSE_SERVICES
        log_info "Talkie is running. Web UI: http://localhost:8765"
        cmd_status
        return
    fi
    log_info "Starting Talkie (services in containers, Web UI runs locally)..."
    [ "$LOCAL_ONLY" -eq 1 ] && log_info "Local-only: module servers will not be started"
    echo ""
    app_check_python
    app_setup_data_dir
    app_install_deps
    log_info "Prebuilding container images..."
    $COMPOSE_CMD build
    log_info "Ensuring infrastructure services are running..."
    local INFRA_SERVICES=(consul-server keydb haproxy)
    local NEED_INFRA=false
    for sn in "${INFRA_SERVICES[@]}"; do
        if ! is_container_running "${CONTAINER_PREFIX}$sn"; then NEED_INFRA=true; break; fi
    done
    if [ "$NEED_INFRA" = true ]; then
        clear_conflicting_talkie_networks
        [ "$COMPOSE_PROJECT_NAME" = "talkie" ] && ensure_talkie_network
        $COMPOSE_CMD up -d "${INFRA_SERVICES[@]}"
        log_info "Waiting for infrastructure (20s)..."
        sleep 20
    fi
    app_health_check_service "Consul" "${CONTAINER_PREFIX}consul-server" "http://localhost:8500/v1/status/leader" || log_warn "Consul health check failed"
    is_container_running "${CONTAINER_PREFIX}keydb" && podman exec "${CONTAINER_PREFIX}keydb" keydb-cli ping > /dev/null 2>&1 && log_info "KeyDB is ready" || log_warn "KeyDB failed"
    app_health_check_service "HAProxy" "${CONTAINER_PREFIX}haproxy" "http://localhost:8404/" || log_warn "HAProxy health check failed"
    log_info "Ensuring application services (Chroma; Ollama is local)..."
    local APP_SERVICES=(chroma)
    local NEED_APP=false
    for sn in "${APP_SERVICES[@]}"; do
        if ! is_container_running "${CONTAINER_PREFIX}$sn"; then NEED_APP=true; break; fi
    done
    if [ "$NEED_APP" = true ]; then
        $COMPOSE_CMD up -d "${APP_SERVICES[@]}"
        log_info "Waiting for application services (20s)..."
        sleep 20
    fi
    if curl -s -f http://localhost:11434/api/tags > /dev/null 2>&1; then
        log_info "Ollama (local) is healthy"
    else
        log_warn "Ollama not responding at localhost:11434. Run: ollama serve"
    fi
    app_health_check_service "Chroma" "${CONTAINER_PREFIX}chroma" "http://localhost:8000/api/v1" || log_warn "Chroma may still be starting"
    app_register_consul_services
    if [ "$LOCAL_ONLY" -eq 0 ]; then
        log_info "Checking module servers..."
        local MODULE_SERVICES=("speech:${CONTAINER_PREFIX}speech:http://localhost:8001/health" "rag:${CONTAINER_PREFIX}rag:http://localhost:8002/health" "browser:${CONTAINER_PREFIX}browser:http://localhost:8003/health")
        local TO_START=() TO_RESTART=()
        for info in "${MODULE_SERVICES[@]}"; do
            IFS=':' read -r sn cn url <<< "$info"
            if is_container_running "$cn"; then
                local hs
                hs=$(podman inspect --format='{{.State.Health.Status}}' "$cn" 2>/dev/null || echo "none")
                if [ "$hs" = "unhealthy" ]; then TO_RESTART+=("$sn"); elif [ -n "$url" ] && ! curl -s -f "$url" > /dev/null 2>&1; then TO_RESTART+=("$sn"); else log_info "$sn is running and healthy"; fi
            else
                TO_START+=("$sn")
            fi
        done
        [ ${#TO_RESTART[@]} -gt 0 ] && $COMPOSE_CMD restart "${TO_RESTART[@]}" && sleep 2
        [ ${#TO_START[@]} -gt 0 ] && $COMPOSE_CMD up -d "${TO_START[@]}" && log_info "Module servers starting..." && sleep 3
        log_info "Consul UI: http://localhost:8500/ui"
    fi
    app_check_ollama_models
    log_info "Starting Talkie Web UI. http://localhost:8765"
    exec pipenv run python run_web.py
}

# View logs
cmd_logs() {
    local service="${1:-}"
    local follow="${2:-}"
    init_compose
    
    if [ -z "$service" ]; then
        log_info "Available services:"
        if _is_production_mode; then
            echo "  talkie-core, consul-server, keydb, haproxy, chroma, speech, rag, browser, healthbeat"
        else
            echo "  Infrastructure: consul-server, keydb, haproxy"
            echo "  Core: chroma (Ollama is local)"
            echo "  Modules: speech, rag, browser, healthbeat"
        fi
        echo ""
        echo "Usage: ./talkie logs <service> [--follow]"
        echo "Example: ./talkie logs consul-server --follow"
        return
    fi
    
    if [ "$follow" = "--follow" ] || [ "$follow" = "-f" ]; then
        podman logs -f "${CONTAINER_PREFIX}$service" 2>/dev/null || log_error "Service '${CONTAINER_PREFIX}$service' not found or not running"
    else
        podman logs "${CONTAINER_PREFIX}$service" 2>/dev/null || log_error "Service '${CONTAINER_PREFIX}$service' not found or not running"
    fi
}

# Interaction history: clear, list (numbered), view #, edit #
cmd_history() {
    local sub="${1:-}"
    shift || true
    if [ -z "$sub" ]; then
        echo "Usage: ./talkie history {clear|list|view <N>|edit <N>}"
        echo "  clear  - delete all interactions"
        echo "  list   - numbered list (newest first, like bash history)"
        echo "  view N - show full details of item N"
        echo "  edit N - open \$EDITOR to edit correction for item N"
        return 1
    fi
    ( cd "$SCRIPT_DIR" && pipenv run python history_cmd.py "$sub" "$@" )
}

# Module subcommands: list, add, rm, update (delegate to module_cmd.py or production shell)
cmd_module() {
    if _is_production_mode; then
        _module_production "$@"
        return $?
    fi
    if [ $# -eq 0 ]; then
        ( cd "$SCRIPT_DIR" && pipenv run python module_cmd.py --help )
        return $?
    fi
    ( cd "$SCRIPT_DIR" && pipenv run python module_cmd.py "$@" )
}

# Production: module list/add/rm without Python (config + podman)
_module_production() {
    local cfg="${TALKIE_CONFIG:-$SCRIPT_DIR/config.yaml}"
    local org="${TALKIE_MARKETPLACE_ORG:-talkie-assistant}"
    local tag="${TALKIE_IMAGE_TAG:-latest}"
    _production_services_list  # sets COMPOSE_SERVICES; we need mods from config
    local mods
    mods=$(grep -E 'enabled:\s*\[' "$cfg" 2>/dev/null | sed 's/.*enabled:\s*\[\([^]]*\)\].*/\1/' | tr ',' ' ' | tr -d '\r')
    [ -z "$mods" ] && mods=""
    local sub="${1:-}"
    shift || true
    case "$sub" in
        list)
            if [ -z "$mods" ]; then
                echo "No modules enabled (edit config modules.enabled)."
                return
            fi
            echo "id     state"
            for m in $mods; do echo "$m  enabled"; done
            ;;
        add)
            local name="${1:-}"
            if [ -z "$name" ]; then
                log_error "Module name required. Usage: ./talkie module add <shortname>"
                exit 1
            fi
            name=$(echo "$name" | sed 's/^talkie-module-//')
            if ! echo "$name" | grep -qE '^[a-zA-Z0-9_-]+$'; then
                log_error "Invalid module name."
                exit 1
            fi
            local image="ghcr.io/${org}/talkie-module-${name}:${tag}"
            log_info "Pulling $image..."
            if ! podman pull "$image"; then
                log_error "podman pull failed. Check network and image name."
                exit 2
            fi
            if echo " $mods " | grep -q " ${name} "; then
                log_info "Module already enabled: $name"
            else
                # Append to modules.enabled (simplified: replace line with extended list)
                local new_list="$mods $name"
                new_list=$(echo "$new_list" | xargs)
                if grep -q 'enabled:\s*\[' "$cfg" 2>/dev/null; then
                    sed -i.bak "s/enabled: \[.*\]/enabled: [${new_list// /, }]/" "$cfg" 2>/dev/null || true
                else
                    echo "modules:" >> "$cfg"
                    echo "  enabled: [$name]" >> "$cfg"
                fi
                log_info "Module added: $name (enabled in config)"
            fi
            echo "Run: ./talkie start to start the new module"
            ;;
        rm)
            local name="${1:-}"
            if [ -z "$name" ]; then
                log_error "Module name required. Usage: ./talkie module rm <shortname>"
                exit 1
            fi
            if ! echo " $mods " | grep -q " ${name} "; then
                log_error "Module not enabled: $name"
                exit 1
            fi
            new_list=$(echo " $mods " | sed "s/ ${name} //" | xargs)
            sed -i.bak "s/enabled: \[.*\]/enabled: [${new_list// /, }]/" "$cfg" 2>/dev/null || true
            log_info "Removed module from config: $name. Run ./talkie stop to stop the container."
            ;;
        list-available|update)
            log_info "Production: use Web UI Marketplace to browse modules, or run from repo: pipenv run python module_cmd.py $sub $*"
            ;;
        *)
            log_error "Unknown subcommand: $sub. Use: list, add, rm"
            exit 1
            ;;
    esac
}

# Run tests by suite: unit (exclude e2e), e2e, synthetic (same as unit), all
cmd_test() {
    local suite="${1:-}"
    if [ -z "$suite" ]; then
        log_info "Usage: ./talkie test {unit|e2e|synthetic|all}"
        echo "  unit     - run unit tests (exclude e2e)"
        echo "  e2e      - run end-to-end browser tests"
        echo "  synthetic - run synthetic/integration tests (currently same as unit)"
        echo "  all      - run all tests"
        exit 1
    fi
    app_check_python
    app_install_deps
    case "$suite" in
        unit)
            log_info "Running unit tests (excluding e2e)..."
            ( cd "$SCRIPT_DIR" && pipenv run pytest tests/ -v -m "not e2e" )
            ;;
        e2e)
            log_info "Running e2e tests..."
            ( cd "$SCRIPT_DIR" && pipenv run pytest tests/e2e/ -v -m e2e )
            ;;
        synthetic)
            log_info "Running synthetic tests..."
            ( cd "$SCRIPT_DIR" && pipenv run pytest tests/ -v -m "not e2e" )
            ;;
        all)
            log_info "Running all tests..."
            ( cd "$SCRIPT_DIR" && pipenv run pytest tests/ -v )
            ;;
        *)
            log_error "Unknown test suite: $suite"
            echo "Use: ./talkie test {unit|e2e|synthetic|all}"
            exit 1
            ;;
    esac
}

# Status and health (combined)
cmd_status() {
    init_compose
    
    log_info "Talkie service status and health:"
    if _is_production_mode; then
        log_debug "Production mode (compose: $COMPOSE_FILE)"
    fi
    echo ""
    
    # Production: show talkie-core (Web UI) first
    if _is_production_mode; then
        echo "Web UI (talkie-core):"
        if podman ps --format "{{.Names}}" | grep -q "^${CONTAINER_PREFIX}talkie-core$"; then
            if curl -s -f http://localhost:8765/ > /dev/null 2>&1; then
                echo -e "  ${GREEN}✓${NC} talkie-core (running, healthy). http://localhost:8765"
            else
                echo -e "  ${YELLOW}!${NC} talkie-core (running, not responding)"
            fi
        else
            echo -e "  ${RED}✗${NC} talkie-core (stopped)"
        fi
        echo ""
    fi
    
    # Capture consul state once (container running + API reachable). Use 127.0.0.1 for curl to avoid IPv6/localhost quirks on macOS.
    _consul_running=0
    _consul_healthy=0
    if podman ps --format "{{.Names}}" 2>/dev/null | grep -q "^${CONTAINER_PREFIX}consul-server$"; then
        _consul_running=1
        for _ in 1 2 3; do
            if curl -s -m 3 http://127.0.0.1:8500/v1/status/leader > /dev/null 2>&1; then
                _consul_healthy=1
                break
            fi
            sleep 1
        done
    fi

    # Infrastructure (running + health)
    echo "Infrastructure:"
    if [ "$_consul_running" -eq 1 ]; then
        if [ "$_consul_healthy" -eq 1 ]; then
            echo -e "  ${GREEN}✓${NC} consul-server (running, healthy)"
        else
            echo -e "  ${YELLOW}!${NC} consul-server (running, not responding)"
        fi
    else
        echo -e "  ${RED}✗${NC} consul-server (stopped)"
    fi
    if podman ps --format "{{.Names}}" | grep -q "^${CONTAINER_PREFIX}keydb$"; then
        if podman exec "${CONTAINER_PREFIX}keydb" keydb-cli ping > /dev/null 2>&1; then
            echo -e "  ${GREEN}✓${NC} keydb (running, healthy)"
        else
            echo -e "  ${YELLOW}!${NC} keydb (running, not responding)"
        fi
    else
        echo -e "  ${RED}✗${NC} keydb (stopped)"
    fi
    if podman ps --format "{{.Names}}" | grep -q "^${CONTAINER_PREFIX}haproxy$"; then
        if curl -s http://localhost:8404 > /dev/null 2>&1; then
            echo -e "  ${GREEN}✓${NC} haproxy (running, healthy)"
        else
            echo -e "  ${YELLOW}!${NC} haproxy (running, not responding)"
        fi
    else
        echo -e "  ${RED}✗${NC} haproxy (stopped)"
    fi

    echo ""
    echo "Core services:"
    if curl -s http://localhost:11434/api/tags > /dev/null 2>&1; then
        echo -e "  ${GREEN}✓${NC} ollama (local, healthy)"
    else
        echo -e "  ${RED}✗${NC} ollama (local, not running - run: ollama serve)"
    fi
    if podman ps --format "{{.Names}}" | grep -q "^${CONTAINER_PREFIX}chroma$"; then
        if curl -s http://localhost:8000/api/v1/heartbeat > /dev/null 2>&1; then
            echo -e "  ${GREEN}✓${NC} chroma (running, healthy)"
        else
            echo -e "  ${YELLOW}!${NC} chroma (running, not responding)"
        fi
    else
        echo -e "  ${RED}✗${NC} chroma (stopped)"
    fi

    echo ""
    echo "Module servers:"
    for entry in "speech:8001" "rag:8002" "browser:8003"; do
        service="${entry%%:*}"
        port="${entry##*:}"
        if podman ps --format "{{.Names}}" | grep -q "^${CONTAINER_PREFIX}$service$"; then
            if curl -s "http://localhost:$port/health" > /dev/null 2>&1; then
                echo -e "  ${GREEN}✓${NC} $service (running, healthy)"
            else
                echo -e "  ${YELLOW}!${NC} $service (running, not responding)"
            fi
        else
            echo -e "  ${RED}✗${NC} $service (stopped)"
        fi
    done
    if podman ps --format "{{.Names}}" | grep -q "^${CONTAINER_PREFIX}healthbeat$"; then
        echo -e "  ${GREEN}✓${NC} healthbeat (running)"
    else
        echo -e "  ${RED}✗${NC} healthbeat (stopped)"
    fi

    echo ""
    echo "Service URLs:"
    echo "  Talkie Web UI: http://localhost:8765"
    if [ "$_consul_running" -eq 1 ]; then
        if [ "$_consul_healthy" -eq 1 ]; then
            echo "  Consul UI: http://127.0.0.1:8500/ui"
        else
            echo -e "  Consul UI: http://127.0.0.1:8500/ui ${YELLOW}(container running, API not responding)${NC}"
        fi
    else
        echo -e "  Consul UI: ${YELLOW}(not running)${NC} http://127.0.0.1:8500/ui  -- start: ./talkie start"
    fi
    if podman ps --format "{{.Names}}" | grep -q "^${CONTAINER_PREFIX}haproxy$"; then
        echo "  HAProxy Stats: http://localhost:8404"
        echo "  HAProxy: http://localhost:8080"
    else
        echo -e "  HAProxy Stats: ${YELLOW}(not running)${NC} http://localhost:8404  -- start: ./talkie start"
        echo -e "  HAProxy: ${YELLOW}(not running)${NC} http://localhost:8080"
    fi
}

# List containers
cmd_ps() {
    init_compose
    
    log_info "Talkie containers:"
    podman ps --filter "name=${CONTAINER_PREFIX}" --format "table {{.Names}}\t{{.Status}}\t{{.Ports}}"
}

# Build container images (no start). Uses per-service Dockerfiles from compose.
# ./talkie build [target] — target: all (default), or a service name (speech, rag, browser, healthbeat, etc.)
cmd_build() {
    local target="${1:-all}"
    local svc

    if _is_production_mode; then
        log_info "Production mode: images are pre-built. Use: ./talkie pull to refresh images."
        return 0
    fi
    if [ "$target" = "web" ]; then
        log_info "Web UI has no container image; nothing to build."
        return 0
    fi

    init_compose
    _validate_compose_config

    if [ "$target" = "all" ]; then
        log_info "Building all images (module images use per-module Dockerfiles)..."
        $COMPOSE_CMD build
        log_info "Build complete"
        return
    fi

    for svc in $COMPOSE_SERVICES; do
        if [ "$target" = "$svc" ]; then
            log_info "Building image for $target..."
            $COMPOSE_CMD build "$target"
            log_info "Build complete: $target"
            return
        fi
    done

    log_error "Unknown build target: $target"
    echo "Use: ./talkie build [all|SERVICE]"
    echo "Services with build: speech, rag, browser, healthbeat (others use pre-built images)."
    exit 1
}

# Pull images (production: pull all from GHCR; dev: pull infra/base images only)
cmd_pull() {
    init_compose
    _validate_compose_config
    if _is_production_mode; then
        log_info "Pulling production images (tag: ${TALKIE_IMAGE_TAG:-latest})..."
        $COMPOSE_CMD pull $COMPOSE_SERVICES
        log_info "Pull complete"
    else
        log_info "Pulling base/infra images (dev mode builds module images locally)..."
        $COMPOSE_CMD pull 2>/dev/null || true
        log_info "Use ./talkie build to build module images."
    fi
}

# Rebuild images and recreate containers: all, changed [REF], or SPECIFIC_SERVICE
cmd_rebuild() {
    local target="${1:-}"
    local ref
    local svc

    if [ -z "$target" ]; then
        log_error "Missing target. Use: ./talkie rebuild {all|changed|SPECIFIC_SERVICE}"
        echo "  all     - rebuild all images and recreate all containers"
        echo "  changed - rebuild and restart only services whose code changed (git diff vs REF, default HEAD)"
        echo "  SERVICE - rebuild and recreate one service (e.g. speech, rag, browser, healthbeat, web)"
        exit 1
    fi

    if [ "$target" = "web" ]; then
        log_info "Web UI has no container image; restarting web process..."
        cmd_web_restart
        return
    fi

    init_compose
    _validate_compose_config

    if [ "$target" = "changed" ]; then
        ref="${2:-HEAD}"
        cmd_restart_changed "$ref"
        return
    fi

    if [ "$target" = "all" ]; then
        init_compose
        _validate_compose_config
        log_info "Rebuilding all images (module images use per-module Dockerfiles)..."
        $COMPOSE_CMD build
        log_info "Recreating all containers..."
        $COMPOSE_CMD up -d --force-recreate
        log_info "Rebuild complete"
        return
    fi

    for svc in $COMPOSE_SERVICES; do
        if [ "$target" = "$svc" ]; then
            init_compose
            _validate_compose_config
            log_info "Rebuilding $target..."
            $COMPOSE_CMD build "$target"
            log_info "Recreating $target container..."
            $COMPOSE_CMD up -d --force-recreate "$target"
            log_info "Rebuild complete: $target"
            return
        fi
    done

    log_error "Unknown rebuild target: $target"
    echo "Use: ./talkie rebuild {all|changed|SPECIFIC_SERVICE}"
    echo "Services: $COMPOSE_SERVICES, web"
    exit 1
}

# Restart only processes whose code has changed (git diff vs HEAD)
# Maps changed paths to: main app, speech, rag, browser, healthbeat; rebuilds image if needed and restarts only affected containers
cmd_restart_changed() {
    local ref="${1:-HEAD}"
    if ! git rev-parse --is-inside-work-tree >/dev/null 2>&1; then
        log_error "Not a git repository. restart-changed requires git to detect code changes."
        exit 1
    fi
    local changed
    changed=$( { git diff --name-only "$ref"; git diff --name-only --cached "$ref"; } 2>/dev/null | sort -u )
    if [ -z "$changed" ]; then
        log_info "No code changes detected (compared to $ref). Nothing to restart."
        return 0
    fi
    local main_changed=0 speech_changed=0 rag_changed=0 browser_changed=0 healthbeat_changed=0 shared_changed=0
    while IFS= read -r path; do
        [ -z "$path" ] && continue
        case "$path" in
            app/*|run.py|run_web.py|run_module_server.py|config.py|config.yaml|persistence/*|llm/*|curation/*|profile/*|web/*|sdk/*)
                main_changed=1
                ;;
            modules/speech/*)
                speech_changed=1
                ;;
            modules/rag/*)
                rag_changed=1
                ;;
            modules/browser/*)
                browser_changed=1
                ;;
            modules/api/healthbeat*)
                healthbeat_changed=1
                ;;
            modules/api/*|modules/__init__.py|modules/discovery.py)
                shared_changed=1
                ;;
        esac
    done <<< "$changed"
    if [ "$shared_changed" -eq 1 ]; then
        speech_changed=1
        rag_changed=1
        browser_changed=1
        healthbeat_changed=1
    fi
    local any_module=$(( speech_changed + rag_changed + browser_changed + healthbeat_changed ))
    if [ "$any_module" -eq 0 ]; then
        if [ "$main_changed" -eq 1 ]; then
            log_info "Only main app code changed (app/, run.py, run_web.py, config, etc.). Restarting main app (web)..."
            cmd_web_restart
        fi
        return 0
    fi
    if [ "$main_changed" -eq 1 ]; then
        log_warn "Main app code also changed. Restart the main app manually to pick up those changes."
    fi
    init_compose
    _validate_compose_config
    local to_restart=""
    [ "$speech_changed" -eq 1 ] && to_restart="$to_restart speech"
    [ "$rag_changed" -eq 1 ]   && to_restart="$to_restart rag"
    [ "$browser_changed" -eq 1 ] && to_restart="$to_restart browser"
    [ "$healthbeat_changed" -eq 1 ] && to_restart="$to_restart healthbeat"
    to_restart=$(echo "$to_restart" | xargs)
    if [ -z "$to_restart" ]; then
        return 0
    fi
    log_info "Rebuilding module image(s) (code changed)..."
    $COMPOSE_CMD build $to_restart 2>/dev/null || $COMPOSE_CMD build $to_restart
    log_info "Restarting only affected containers: $to_restart"
    $COMPOSE_CMD restart $to_restart
    log_info "Done. Restarted: $to_restart"
}

# Download assets (Vosk + Whisper models, dirs; optional rifai PDFs). Sync, only missing.
VOSK_MODEL_NAME="vosk-model-small-en-us-0.15"
VOSK_URL="https://alphacephei.com/vosk/models/${VOSK_MODEL_NAME}.zip"

cmd_download() {
    local do_rifai="${1:-}"
    log_info "Creating directories: models, downloads, data..."
    mkdir -p models downloads data
    # Vosk: sync, only if missing
    if [ -d "models/${VOSK_MODEL_NAME}" ]; then
        log_info "Vosk model already present: models/${VOSK_MODEL_NAME}"
    else
        log_info "Downloading Vosk model: ${VOSK_MODEL_NAME}..."
        if command -v curl &>/dev/null; then
            curl -sL -o "models/${VOSK_MODEL_NAME}.zip" "$VOSK_URL" || { log_error "Download failed."; exit 1; }
        else
            wget -q -O "models/${VOSK_MODEL_NAME}.zip" "$VOSK_URL" || { log_error "Download failed."; exit 1; }
        fi
        log_info "Extracting to models/${VOSK_MODEL_NAME}..."
        ( cd models && unzip -o -q "${VOSK_MODEL_NAME}.zip" && rm -f "${VOSK_MODEL_NAME}.zip" ) || { log_error "Unzip failed."; exit 1; }
        log_info "Vosk model ready: models/${VOSK_MODEL_NAME}"
    fi
    # Whisper: sync, only if not already cached (faster-whisper uses Hugging Face cache)
    if (stt_engine=$(grep -E "^\s*engine:\s*" config.yaml 2>/dev/null | head -1); echo "$stt_engine" | grep -qi "whisper"); then
        pipenv run python -c '
import sys
from pathlib import Path
root = Path(".").resolve()
if str(root) not in sys.path:
    sys.path.insert(0, str(root))
try:
    from config import load_config
    cfg = load_config()
    stt = cfg.get("stt") or {}
    if (stt.get("engine") or "vosk").lower() != "whisper":
        sys.exit(0)
    whisper_cfg = stt.get("whisper") or {}
    model = (whisper_cfg.get("model_path") or "base").strip() or "base"
    from modules.speech.stt.whisper_engine import ensure_whisper_model_downloaded
    ensure_whisper_model_downloaded(model)
    print("Whisper", model, "ready")
except ImportError as e:
    if "faster_whisper" in str(e):
        sys.exit(2)
    raise
' 2>/dev/null
        local ret=$?
        if [ "$ret" -eq 0 ]; then
            log_info "Whisper model ready (cached or downloaded)"
        elif [ "$ret" -eq 2 ]; then
            log_info "Whisper not installed (faster_whisper); skip. Use STT engine whisper to pre-download."
        else
            log_warn "Whisper model pre-download failed or skipped (check config and pipenv)."
        fi
    fi
    # Ollama: sync pull/update default models (tinyllama, phi, nomic-embed-text) and config's model_name + embedding_model
    if curl -s -f http://localhost:11434/api/tags >/dev/null 2>&1; then
        local ollama_models="tinyllama phi nomic-embed-text"
        local model_name embed_model
        [ -f config.yaml ] && model_name=$(grep -E "^\s*model_name:" config.yaml | head -1 | sed 's/.*model_name:\s*\([^ ]*\).*/\1/' | tr -d '"')
        [ -n "$model_name" ] && ollama_models="$ollama_models $model_name"
        [ -f config.yaml ] && grep -q "embedding_model:" config.yaml && embed_model=$(grep -E "^\s*embedding_model:" config.yaml | head -1 | sed 's/.*embedding_model:\s*\([^ ]*\).*/\1/' | tr -d '"')
        [ -n "$embed_model" ] && ollama_models="$ollama_models $embed_model"
        for m in $(echo "$ollama_models" | tr ' ' '\n' | sort -u); do
            [ -z "$m" ] && continue
            log_info "Pulling/updating Ollama model '$m'..."
            ollama pull "$m" || log_warn "ollama pull $m failed"
        done
    else
        log_info "Ollama not running; skip. Run 'ollama serve' and re-run ./talkie download to pull/update models."
    fi
    if [ "$do_rifai" = "rifai" ] || [ "$do_rifai" = "--rifai" ]; then
        log_info "Running rifai_scholar_downloader (downloads/abdalla_rifai_publications_open_pdfs)..."
        pipenv run python -m rifai_scholar_downloader || log_warn "rifai download failed or skipped."
    else
        log_info "Optional: run ./talkie download rifai to fetch Scholar PDFs to downloads/."
    fi
}

# Doctor: check environment and suggest fixes
cmd_doctor() {
    local ok=0
    log_info "Talkie doctor: checking environment..."
    echo ""
    if ! command -v podman &>/dev/null; then
        echo -e "  ${RED}✗${NC} Podman not found. Install: brew install podman (macOS) or see https://podman.io"
        ok=1
    else
        echo -e "  ${GREEN}✓${NC} Podman: $(podman --version 2>/dev/null || echo present)"
    fi
    _set_compose_mode
    if _is_production_mode; then
        echo -e "  ${GREEN}✓${NC} Mode: production (compose: compose.production.yaml)"
        if [ ! -f "${TALKIE_CONFIG:-$SCRIPT_DIR/config.yaml}" ]; then
            echo -e "  ${RED}✗${NC} config.yaml not found. Copy config.yaml.example to config.yaml or set TALKIE_CONFIG"
            ok=1
        else
            echo -e "  ${GREEN}✓${NC} config.yaml present"
        fi
        if [ -z "$(grep -E 'enabled:\s*\[' "${TALKIE_CONFIG:-$SCRIPT_DIR/config.yaml}" 2>/dev/null)" ]; then
            echo -e "  ${YELLOW}!${NC} modules.enabled not set in config. Add e.g. modules.enabled: [speech, rag, browser]"
        fi
    else
        echo -e "  ${GREEN}✓${NC} Mode: development (compose: compose.yaml)"
        if [ ! -f "$SCRIPT_DIR/config.yaml" ]; then
            echo -e "  ${RED}✗${NC} config.yaml not found. Copy config.yaml.example to config.yaml"
            ok=1
        else
            echo -e "  ${GREEN}✓${NC} config.yaml present"
        fi
        if [ ! -f "$SCRIPT_DIR/compose.yaml" ]; then
            echo -e "  ${RED}✗${NC} compose.yaml not found (not in repo root?)"
            ok=1
        fi
        if ! command -v pipenv &>/dev/null; then
            echo -e "  ${YELLOW}!${NC} pipenv not found. Run: pip3 install --user pipenv"
        else
            echo -e "  ${GREEN}✓${NC} pipenv present"
        fi
    fi
    echo ""
    log_info "Container health (if running):"
    init_compose 2>/dev/null || true
    for svc in $COMPOSE_SERVICES; do
        if podman ps --format "{{.Names}}" 2>/dev/null | grep -q "^${CONTAINER_PREFIX}${svc}$"; then
            local health
            health=$(podman inspect --format='{{.State.Health.Status}}' "${CONTAINER_PREFIX}${svc}" 2>/dev/null || echo "none")
            if [ "$health" = "healthy" ]; then
                echo -e "  ${GREEN}✓${NC} $svc (healthy)"
            elif [ "$health" = "unhealthy" ]; then
                echo -e "  ${RED}✗${NC} $svc (unhealthy). Try: ./talkie restart $svc"
                ok=1
            else
                echo -e "  ${YELLOW}!${NC} $svc (running, no healthcheck)"
            fi
        else
            echo -e "  - $svc (stopped)"
        fi
    done
    echo ""
    if [ "$ok" -eq 0 ]; then
        log_info "Doctor: no issues found."
    else
        log_warn "Doctor: fix the issues above, then run ./talkie start or ./talkie app"
        exit 2
    fi
}

# Clean up
cmd_clean() {
    local what="${1:-containers}"
    init_compose
    
    case "$what" in
        containers)
            log_warn "Stopping and removing all Talkie containers..."
            $COMPOSE_CMD down
            log_info "Containers cleaned up"
            ;;
        volumes)
            log_warn "Removing all Talkie volumes (this will delete data)..."
            read -p "Are you sure? This will delete all data! [y/N] " -n 1 -r
            echo
            if [[ $REPLY =~ ^[Yy]$ ]]; then
                $COMPOSE_CMD down -v
                log_info "Volumes removed"
            else
                log_info "Cancelled"
            fi
            ;;
        all)
            log_warn "Removing all Talkie containers and volumes (this will delete data)..."
            read -p "Are you sure? This will delete all data! [y/N] " -n 1 -r
            echo
            if [[ $REPLY =~ ^[Yy]$ ]]; then
                $COMPOSE_CMD down -v
                podman volume prune -f 2>/dev/null || true
                log_info "Everything cleaned up"
            else
                log_info "Cancelled"
            fi
            ;;
        *)
            log_error "Unknown clean option: $what"
            echo "Usage: ./talkie clean [containers|volumes|all]"
            exit 1
            ;;
    esac
}

# Show usage
usage() {
    cat << EOF
Talkie Service Management CLI

Usage: ./talkie [--dev|--production] <command> [options]

  --dev, -d       Development mode: compose.yaml, build from source, Web UI via pipenv.
  --production    Production mode: compose.production.yaml, image-only, Web UI in talkie-core container.
  (Default: dev when run from repo with compose.yaml + modules/; else production.)

Commands:
  start [target]
        Start services (default: all). Target: all, core, modules, web, or a
        single service (consul-server, keydb, haproxy, chroma, speech, rag,
        browser, healthbeat).
        - all: consul + keydb + haproxy + chroma + modules + Web UI (http://localhost:8765)
        - core: Chroma only (Ollama is local - run: ollama serve)
        - modules: speech, rag, browser, healthbeat
        - web: Web UI only (run_web.py, port 8765)

  stop [target]
        Stop services (default: all). Same targets as start.

  restart [target]
        Restart services (default: all). Same targets as start.
        - restart changed [REF]: Restart/rebuild only services whose code changed (git diff vs REF, default HEAD).

  build [target]
        Build container images (no start). Uses per-module Dockerfiles for speech, rag, browser, healthbeat.
        (Production: no build; use ./talkie pull to refresh images.)
        - build: build all images that have a build section (module images)
        - build SERVICE: build one service (e.g. speech, rag, browser, healthbeat)

  pull            Pull images (production: from GHCR; dev: base/infra images only).

  rebuild {all|changed|SPECIFIC_SERVICE}
        Rebuild images and recreate containers.
        - all: rebuild all images, then recreate all containers
        - changed [REF]: rebuild and restart only services whose code changed (git diff vs REF, default HEAD)
        - SERVICE: rebuild and recreate one service (e.g. speech, rag, browser, healthbeat); web = restart web process

  status [web]
        Show status and health. No argument: all services + health checks. With web: Web UI only.

  app [--local-only]
        Bring up container services then run the Web UI (foreground).
        - app: Web UI at http://localhost:8765
        - app --local-only: Skip module containers; app may start them as subprocesses

  ps      List running containers

  logs <service> [--follow]
        View logs for a service
        Use --follow or -f to follow logs
        Example: ./talkie logs consul-server --follow

  download [rifai]
        Fetch assets not in git (sync, only missing). Creates models/, downloads/, data/.
        - download: Vosk + Whisper (if config uses whisper) + Ollama models (tinyllama, phi, config model_name/embedding_model)
        - download rifai: also run rifai_scholar_downloader (PDFs to downloads/)

  clean [containers|volumes|all]
        Clean up resources
        - containers: Stop and remove containers
        - volumes: Remove volumes (deletes data)
        - all: Remove everything

  doctor       Check environment (podman, config, mode, container health) and suggest fixes.

  history {clear|list|view <N>|edit <N>}
        Interaction history (numbered, newest first)
        - clear: delete all interactions
        - list: numbered list (like bash history)
        - view N: show full details of item N
        - edit N: open \$EDITOR to edit correction for item N

  module {list|list-available|add|rm|update}
        Manage modules (git submodules under modules/).
        - list              List installed modules (id, name, version, description)
        - list-available    List all marketplace modules with installation state
        - add <module>      Add a module (shortname or talkie-module-<name>)
        - rm <module>       Remove a module (shortname; deinit + git rm)
        - update [module|all]   Init/update submodules (default: all)

  test {unit|e2e|synthetic|all}
        Run tests by suite.
        - unit     - unit tests (exclude e2e)
        - e2e      - end-to-end browser tests
        - synthetic - synthetic/integration (currently same as unit)
        - all      - all tests

  help    Show this help message

Examples:
  ./talkie start                    # Start all services + Web UI (http://localhost:8765)
  ./talkie start web                 # Start Web UI only
  ./talkie restart haproxy           # Restart HAProxy only
  ./talkie restart web               # Restart Web UI only
  ./talkie stop web                  # Stop Web UI
  ./talkie status                    # Status and health of all services
  ./talkie status web                # Web UI only
  ./talkie app                      # Start services + Web UI (foreground)
  ./talkie app --local-only         # Start Web UI only (no module containers)
  ./talkie logs consul-server -f   # Follow Consul logs
  ./talkie download                  # Vosk + Whisper + Ollama (tinyllama, phi, config)
  ./talkie download rifai            # + Scholar PDFs to downloads/
  ./talkie build                    # Build all module images (per-module Dockerfiles)
  ./talkie build rag                # Build RAG module image only
  ./talkie restart changed          # Restart/rebuild only containers whose code changed
  ./talkie rebuild all              # Rebuild all images and recreate all containers
  ./talkie rebuild changed          # Rebuild/restart only services with code changes
  ./talkie rebuild speech           # Rebuild and recreate speech service only
  ./talkie clean containers         # Clean up containers
  ./talkie history list             # Numbered interaction history (newest first)
  ./talkie history view 1           # View details of most recent item
  ./talkie history edit 1            # Edit correction for item 1 (\$EDITOR)
  ./talkie module list              # List installed modules
  ./talkie module list-available     # List all marketplace modules + state
  ./talkie module add speech        # Add speech module (submodule)
  ./talkie module update all        # Init/update all submodules
  ./talkie test unit                # Unit tests only
  ./talkie test e2e                 # E2E browser tests
  ./talkie test all                 # All tests

EOF
}

# Main command dispatcher
main() {
    local command="${1:-help}"
    shift || true

    case "$command" in
        start)
            cmd_start "${1:-all}"
            ;;
        stop)
            cmd_stop "${1:-all}"
            ;;
        restart)
            if [ "${1:-}" = "changed" ]; then
                shift
                cmd_restart_changed "${1:-HEAD}"
            else
                cmd_restart "${1:-all}"
            fi
            ;;
        app)
            cmd_app "$@"
            ;;
        logs)
            cmd_logs "$1" "$2"
            ;;
        status)
            if [ "${1:-}" = "web" ]; then
                cmd_web_status
            else
                cmd_status
            fi
            ;;
        ps)
            cmd_ps
            ;;
        download)
            cmd_download "$1"
            ;;
        build)
            cmd_build "$1"
            ;;
        pull)
            cmd_pull
            ;;
        rebuild)
            cmd_rebuild "$1" "$2"
            ;;
        clean)
            cmd_clean "${1:-containers}"
            ;;
        doctor)
            cmd_doctor
            ;;
        history)
            cmd_history "$@"
            ;;
        module)
            cmd_module "$@"
            ;;
        test)
            cmd_test "$1"
            ;;
        doctor)
            cmd_doctor
            ;;
        help|--help|-h)
            usage
            ;;
        *)
            log_error "Unknown command: $command"
            echo ""
            usage
            exit 1
            ;;
    esac
}

main "$@"
